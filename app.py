import streamlit as st
import pandas as pd
import numpy as np
import io
import json
import xlsxwriter
from docx import Document
from docx.shared import Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.shared import OxmlElement
from docx.oxml.ns import qn
import docx.opc.constants
import re

# ==========================================
# PART 1: é…ç½®åŒºåŸŸ
# ==========================================

COMMON_METRICS = {
    "spend": ["èŠ±è´¹é‡‘é¢(USD)", "èŠ±è´¹é‡‘é¢", "Amount Spent", "Cost", "èŠ±è´¹"],
    "roas": ["å¹¿å‘ŠèŠ±è´¹å›æŠ¥ (ROAS) - è´­ç‰©", "ROAS", "Purchase ROAS", "Return on Ad Spend"],
    "purchases": ["è´­ä¹°æ¬¡æ•°", "æˆæ•ˆ", "Purchases", "Results", "Website Purchases"],
    "cpa": ["å•æ¬¡è´­ä¹°è´¹ç”¨", "Cost per Purchase", "Cost per Result", "CPA"],
    "ctr": ["é“¾æ¥ç‚¹å‡»ç‡", "CTR", "Link CTR"],
    "cpm": ["åƒæ¬¡å±•ç¤ºè´¹ç”¨", "CPM"],
    "clicks": ["ç‚¹å‡»", "é“¾æ¥ç‚¹å‡»", "Clicks", "Link Clicks"],
    "impressions": ["æ›å…‰", "å±•ç¤ºæ¬¡æ•°", "Impressions"],
    "purchase_value": ["è´­ä¹°ä»·å€¼", "è´­ç‰©ä»·å€¼", "Purchase Value", "Conversion Value", "Total Value"],
    "aov": ["å•æ¬¡è´­ä¹°ä»·å€¼", "å•æ¬¡è´­ç‰©ä»·å€¼"]
}

SHEET_MAPPINGS = {
    "æ•´ä½“æ•°æ®": {
        **COMMON_METRICS,
        "date_range": ["æ—¶é—´èŒƒå›´", "Date Range", "Time"],
        "clicks_all": ["ç‚¹å‡»", "ç‚¹å‡»(å…¨éƒ¨)", "Clicks (All)"],
        "landing_page_views": ["è½åœ°é¡µæµè§ˆé‡", "è½åœ°é¡µ", "Landing Page Views", "Landing", "è½åœ°é¡µæµè§ˆ"],
        # âœ… è¿™é‡Œçš„å®šä¹‰åªåšå‚è€ƒï¼Œå®é™…é€»è¾‘åœ¨ find_column_smart ä¸­åŠ å¼º
        "add_to_cart": ["åŠ å…¥è´­ç‰©è½¦", "åŠ è´­", "Add to Cart", "Website Adds to Cart", "Adds to Cart", "Cart"], 
        "initiate_checkout": ["ç»“è´¦å‘èµ·æ¬¡æ•°", "ç»“è´¦", "Initiate Checkout", "Checkouts"],
        "rate_click_to_lp": ["ç‚¹å‡»-è½åœ°é¡µæµè§ˆè½¬åŒ–ç‡"],
        "rate_lp_to_atc": ["è½åœ°é¡µæµè§ˆ-åŠ è´­è½¬åŒ–ç‡"],
        "rate_atc_to_ic": ["åŠ è´­-ç»“è´¦è½¬åŒ–ç‡"],
        "rate_ic_to_pur": ["ç»“è´¦-è´­ä¹°è½¬åŒ–ç‡"]
    },
    "åˆ†æ—¶æ®µæ•°æ®": {
        **COMMON_METRICS,
        "date_range": ["æ—¶é—´èŒƒå›´", "Day", "Date", "Reporting Starts"],
        "landing_page_views": ["è½åœ°é¡µæµè§ˆé‡", "Landing Page Views"],
        "add_to_cart": ["åŠ å…¥è´­ç‰©è½¦", "åŠ è´­", "Add to Cart"],
        "initiate_checkout": ["ç»“è´¦å‘èµ·æ¬¡æ•°", "Initiate Checkout"],
    },
    "å¼‚å¸¸æŒ‡æ ‡": {"anomaly_metric_name": ["å¼‚å¸¸æŒ‡æ ‡"], "mom_change": ["ç¯æ¯”"]},
    "å¹¿å‘Šæ¶æ„": {**COMMON_METRICS, "dimension_item": ["å¹¿å‘Šç±»å‹"]},
    "å—ä¼—ç»„": {
        **COMMON_METRICS,
        "dimension_item": ["å¹¿å‘Šç»„", "å¹¿å‘Šç»„Id", "Ad Set Name"],
        "custom_audience_settings": ["è®¾ç½®çš„è‡ªå®šä¹‰å—ä¼—", "Custom Audiences"],
        "converting_keywords": ["äº§ç”Ÿæˆæ•ˆçš„å…³é”®è¯", "Interests"],
        "converting_countries": ["äº§ç”Ÿæˆæ•ˆçš„å›½å®¶", "å›½å®¶", "Country"],
        "converting_genders": ["äº§ç”Ÿæˆæ•ˆçš„æ€§åˆ«", "æ€§åˆ«", "Gender"],
        "converting_ages": ["äº§ç”Ÿæˆæ•ˆçš„å¹´é¾„", "å¹´é¾„", "Age"]
    },
    "å—ä¼—ç±»å‹": {**COMMON_METRICS, "dimension_item": ["å—ä¼—ç±»å‹"]},
    "å›½å®¶": {**COMMON_METRICS, "dimension_item": ["å›½å®¶/åœ°åŒº", "å›½å®¶"]},
    "å¹´é¾„": {**COMMON_METRICS, "dimension_item": ["å¹´é¾„"]},
    "æ€§åˆ«": {**COMMON_METRICS, "dimension_item": ["æ€§åˆ«"]},
    "å¹³å°&ç‰ˆä½": {**COMMON_METRICS, "dimension_item": ["å¹³å°&ç‰ˆä½"]},
    "ç´ æ": {
        **COMMON_METRICS,
        "content_item": ["ç´ æ", "Ad Name", "Creative Name"],
        "cvr_lp_to_pur": ["è½åœ°é¡µæµè§ˆ-è´­ä¹°è½¬åŒ–ç‡"]
    },
    "è½åœ°é¡µ": {
        **COMMON_METRICS,
        "content_item": ["è½åœ°é¡µurl", "è½åœ°é¡µ", "Website URL"],
        "ctr_all": ["æ›å…‰-ç‚¹å‡»è½¬åŒ–ç‡"],
        "rate_lp_to_atc": ["è½åœ°é¡µæµè§ˆ-åŠ è´­è½¬åŒ–ç‡"]
    }
}

GROUP_CONFIG = {
    "Master_Overview": ["æ•´ä½“æ•°æ®", "åˆ†æ—¶æ®µæ•°æ®", "å¼‚å¸¸æŒ‡æ ‡"],
    "Master_Breakdown": ["å¹¿å‘Šæ¶æ„", "å—ä¼—ç»„", "å—ä¼—ç±»å‹", "å›½å®¶", "å¹´é¾„", "æ€§åˆ«", "å¹³å°&ç‰ˆä½"],
    "Master_Creative": ["ç´ æ", "è½åœ°é¡µ"]
}

REPORT_MAPPING = {
    "spend": "èŠ±è´¹ ($)", "roas": "ROAS", "purchases": "è´­ä¹°æ¬¡æ•°", "purchase_value": "è´­ä¹°æ€»ä»·å€¼",
    "cpa": "CPA ($)", "ctr": "CTR (%)", "cpm": "CPM ($)", "aov": "å®¢å•ä»·",
    "impressions": "å±•ç°é‡", "clicks_all": "ç‚¹å‡»é‡ (All)", "clicks": "ç‚¹å‡»é‡ (All)", "ctr_all": "ç‚¹å‡»ç‡ (All)",
    "landing_page_views": "è½åœ°é¡µè®¿é—®é‡", "add_to_cart": "åŠ è´­æ¬¡æ•°", "initiate_checkout": "ç»“è´¦å‘èµ·æ•° (IC)",
    "rate_click_to_lp": "ç‚¹å‡» â†’ è½åœ°é¡µè®¿é—®è½¬åŒ–ç‡", "rate_lp_to_atc": "è½åœ°é¡µ â†’ åŠ è´­è½¬åŒ–ç‡",
    "rate_atc_to_ic": "åŠ è´­ â†’ è´­ä¹°è½¬åŒ–ç‡", "rate_ic_to_pur": "è´­ä¹°è½¬åŒ–ç‡",
    "cvr_purchase": "ç‚¹å‡» â†’ è´­ä¹°è½¬åŒ–ç‡", "cvr_lp_to_pur": "CVR (å…¨ç«™è½¬åŒ–ç‡)",
    "date_range": "æ—¥æœŸ/æ—¶æ®µ", "campaign_type": "æŠ•æ”¾æ¨¡å¼", "adset_name": "å¹¿å‘Šç»„ID",
    "custom_audience_settings": "è‡ªå®šä¹‰å—ä¼—æº", "converting_keywords": "é«˜æ½œå…´è¶£è¯", 
    "country": "å›½å®¶", "creative_name": "ç´ æåç§°", "placement": "ç‰ˆä½",
    "landing_page_url": "é¡µé¢ URL", "mom_change": "ç¯æ¯”æ³¢åŠ¨", "anomaly_metric_name": "å¼‚å¸¸é¡¹",
    "converting_countries": "äº§ç”Ÿæˆæ•ˆçš„å›½å®¶", "converting_genders": "äº§ç”Ÿæˆæ•ˆçš„æ€§åˆ«", "converting_ages": "äº§ç”Ÿæˆæ•ˆçš„å¹´é¾„"
}

FIELD_ALIASES = {
    "spend": ["spend", "cost", "èŠ±è´¹"],
    "purchases": ["purchases", "results", "æˆæ•ˆ", "è´­ä¹°"],
    "clicks": ["clicks", "ç‚¹å‡»"],
    "impressions": ["impressions", "å±•ç¤º"],
    "add_to_cart": ["add_to_cart", "cart", "åŠ è´­"],
    "initiate_checkout": ["initiate_checkout", "checkout", "ç»“è´¦"],
    "landing_page_views": ["landing_page_views", "è½åœ°é¡µ", "landing"]
}

# ==========================================
# PART 2: æ ¸å¿ƒå·¥å…·å‡½æ•°
# ==========================================

def clean_numeric_strict(val): 
    if pd.isna(val): return 0.0
    if isinstance(val, (int, float)): return float(val)
    # å¤„ç†ç‰¹æ®Šå­—ç¬¦
    val_str = str(val).strip().replace('$', '').replace('Â¥', '').replace(',', '')
    if val_str == '-' or val_str == 'â€”': return 0.0 # å¤„ç† Excel é‡Œçš„æ¨ªæ 
    if '%' in val_str: 
        val_str = val_str.replace('%', '')
        try: return float(val_str) / 100.0
        except: return 0.0
    try: return float(val_str)
    except: return 0.0

def clean_numeric(val):
    # ä¸ strict ç±»ä¼¼ï¼Œä½†ç”¨äº DataFrame applyï¼Œå®½å®¹åº¦é«˜ä¸€ç‚¹
    if pd.isna(val): return 0.0
    if isinstance(val, (int, float)): return float(val)
    val_str = str(val).strip().replace('$', '').replace('Â¥', '').replace(',', '')
    if val_str == '-' or val_str == 'â€”': return 0.0
    if '%' in val_str: 
        val_str = val_str.replace('%', '')
        try: return float(val_str) / 100.0 
        except: return 0.0
    try: return float(val_str)
    except: return val 

def safe_div(n, d, m=1.0):
    n_val, d_val = clean_numeric_strict(n), clean_numeric_strict(d)
    return (n_val / d_val * m) if d_val > 0 else 0.0

def find_column_smart(df, target_key, keywords):
    """
    æ™ºèƒ½åˆ—ååŒ¹é…ï¼š
    1. ä¼˜å…ˆå®Œå…¨åŒ¹é…
    2. å…¶æ¬¡æ¨¡ç³ŠåŒ¹é…ï¼ˆåŒ…å«å…³é”®è¯ï¼‰
    3. âœ… æ ¸å¿ƒä¿®æ­£ï¼šæ’é™¤ 'Cost', 'Value', 'Rate' ç­‰å¹²æ‰°è¯ï¼Œé˜²æ­¢æŠŠ 'Cost per Add to Cart' è¯†åˆ«ä¸º 'Add to Cart'
    """
    # æ’é™¤è¯åˆ—è¡¨ï¼šå¦‚æœç›®æ ‡æ˜¯è®¡æ•°ç±»æŒ‡æ ‡ï¼ˆåŠ è´­ã€ç»“è´¦ã€è´­ä¹°ï¼‰ï¼Œä¸èƒ½åŒ…å«è¿™äº›è¯
    exclusion_list = []
    if target_key in ['add_to_cart', 'initiate_checkout', 'purchases', 'clicks', 'impressions']:
        exclusion_list = ['cost', 'cpa', 'value', 'rate', 'è´¹ç”¨', 'ä»·å€¼', 'ç‡', 'å•æ¬¡']
    
    # 1. ä¼˜å…ˆçº§æœ€é«˜ï¼šå…¨å­—åŒ¹é… (Case Insensitive)
    for col in df.columns:
        for kw in keywords:
            if kw.lower() == col.lower():
                return col

    # 2. ä¼˜å…ˆçº§ç¬¬äºŒï¼šåŒ…å«åŒ¹é… (ä½†è¦æ£€æŸ¥æ’é™¤è¯)
    for col in df.columns:
        col_lower = col.lower()
        # å¿…é¡»åŒ…å«å…³é”®è¯
        is_match = False
        for kw in keywords:
            if kw.lower() in col_lower:
                is_match = True
                break
        
        if is_match:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ’é™¤è¯
            has_exclusion = False
            for exc in exclusion_list:
                if exc in col_lower:
                    has_exclusion = True
                    break
            
            if not has_exclusion:
                return col
    
    return None

def calc_metrics_dict(df_chunk):
    res = {}
    if df_chunk.empty: return res
    sums = {}
    targets = ['spend', 'clicks', 'impressions', 'purchases', 'purchase_value',
               'landing_page_views', 'add_to_cart', 'initiate_checkout']
    
    for t in targets:
        col = find_column_smart(df_chunk, t, FIELD_ALIASES.get(t, [t]))
        if col:
             sums[t] = df_chunk[col].apply(clean_numeric_strict).sum()
        else:
             sums[t] = 0.0

    res.update(sums)
    res['roas'] = safe_div(sums.get('purchase_value'), sums.get('spend'))
    res['cpm'] = safe_div(sums.get('spend'), sums.get('impressions'), 1000)
    res['cpc'] = safe_div(sums.get('spend'), sums.get('clicks'))
    res['ctr'] = safe_div(sums.get('clicks'), sums.get('impressions'))
    res['cpa'] = safe_div(sums.get('spend'), sums.get('purchases'))
    res['cvr_purchase'] = safe_div(sums.get('purchases'), sums.get('clicks'))
    res['rate_click_to_lp'] = safe_div(sums.get('landing_page_views'), sums.get('clicks'))
    res['rate_lp_to_atc']   = safe_div(sums.get('add_to_cart'), sums.get('landing_page_views'))
    res['rate_atc_to_ic']   = safe_div(sums.get('initiate_checkout'), sums.get('add_to_cart'))
    res['rate_ic_to_pur']   = safe_div(sums.get('purchases'), sums.get('initiate_checkout'))
    res['aov'] = safe_div(sums.get('purchase_value'), sums.get('purchases'))
    return res 

def format_cell(key, val, is_mom=False):
    if isinstance(val, str): return val
    if is_mom: return val if key == 'date_range' else f"{val:+.2%}"
    k = str(key).lower()
    if 'roas' in k: return f"{val:.2f}"
    if any(x in k for x in ['rate', 'ctr', 'cvr']): return f"{val:.2%}" 
    if any(x in k for x in ['spend', 'cpm', 'cpc', 'value', 'aov', 'cpa']): return f"{val:,.2f}"
    if any(x in k for x in ['purchases', 'cart', 'click', 'impressions', 'checkout']): return f"{val:,.0f}"
    return f"{val}"

def add_df_to_word(doc, df, title, level=1):
    if df.empty: return
    doc.add_heading(title, level=level)
    t = doc.add_table(rows=df.shape[0]+1, cols=df.shape[1])
    t.style = 'Table Grid'
    for j, col in enumerate(df.columns):
        cell = t.cell(0, j)
        cell.text = str(col)
        cell.paragraphs[0].runs[0].font.bold = True
        cell.paragraphs[0].runs[0].font.size = Pt(8)
    for i in range(df.shape[0]):
        for j in range(df.shape[1]):
            val = df.iat[i, j]
            cell = t.cell(i+1, j)
            cell.text = str(val)
            for p in cell.paragraphs:
                for r in p.runs: r.font.size = Pt(8)
    doc.add_paragraph("\n")

# ==========================================
# PART 3: ä¸»é€»è¾‘ç±» (ETL + è°ƒè¯•è¯Šæ–­)
# ==========================================

class AdReportProcessor:
    def __init__(self, raw_file, bench_file=None):
        self.raw_file = raw_file
        self.bench_file = bench_file
        self.processed_dfs = {}
        self.merged_dfs = {}
        self.final_json = {}
        self.doc = Document()
        self.debug_log = [] # ä¸“é—¨ç”¨äºå‰ç«¯æ˜¾ç¤ºçš„è¯Šæ–­æ—¥å¿—

    def find_sheet_fuzzy(self, target, actual_sheets):
        for actual in actual_sheets:
            if target.strip().lower() == actual.strip().lower(): return actual
        for actual in actual_sheets:
            if target in actual: return actual
        return None

    def process_etl(self):
        xls = pd.ExcelFile(self.raw_file)
        
        for config_sheet_name, mapping in SHEET_MAPPINGS.items():
            actual_sheet_name = self.find_sheet_fuzzy(config_sheet_name, xls.sheet_names)
            
            if actual_sheet_name:
                df = pd.read_excel(xls, sheet_name=actual_sheet_name)
                df.columns = [str(c).strip() for c in df.columns]
                
                final_cols = {}
                # âœ… 1. æ™ºèƒ½åŒ¹é…åˆ—
                for std_col, raw_col_options in mapping.items():
                    # ç»“åˆé…ç½®çš„åˆ«å + æ™ºèƒ½æ’é™¤é€»è¾‘
                    search_keywords = raw_col_options
                    matched_col = find_column_smart(df, std_col, search_keywords)
                    
                    if matched_col:
                        final_cols[std_col] = matched_col
                        # ğŸ“ è®°å½•å…³é”®æŒ‡æ ‡çš„åŒ¹é…æƒ…å†µåˆ°æ—¥å¿—
                        if config_sheet_name == "æ•´ä½“æ•°æ®" and std_col in ["add_to_cart", "initiate_checkout"]:
                            sample_vals = df[matched_col].head(3).tolist()
                            self.debug_log.append(f"âœ… [æ•´ä½“æ•°æ®] æˆåŠŸåŒ¹é… '{std_col}' -> åŸåˆ—å '{matched_col}' | å‰3è¡Œæ•°æ®: {sample_vals}")
                
                # âœ… 2. å…œåº•åŒ¹é…ï¼šå¦‚æœæ²¡æ‰¾åˆ°åŠ è´­ï¼Œå°è¯•æš´åŠ›æœç´¢åŒ…å« "cart" ä¸”ä¸å« "cost" çš„åˆ—
                if config_sheet_name == "æ•´ä½“æ•°æ®" and "add_to_cart" not in final_cols:
                    for c in df.columns:
                        if "cart" in c.lower() and "cost" not in c.lower() and "value" not in c.lower():
                            final_cols["add_to_cart"] = c
                            self.debug_log.append(f"âš ï¸ [æ•´ä½“æ•°æ®] æš´åŠ›åŒ¹é… '{c}' ä¸º add_to_cart")
                            break

                # 3. åˆ›å»º Clean DF
                if final_cols:
                    df_clean = df[list(final_cols.values())].rename(columns={v: k for k, v in final_cols.items()})
                else:
                    df_clean = pd.DataFrame()
                
                # 4. è¡¥å…¨ç¼ºå¤±åˆ—ä¸º 0
                for expected_col in mapping.keys():
                    if expected_col not in df_clean.columns:
                        df_clean[expected_col] = 0.0
                        if config_sheet_name == "æ•´ä½“æ•°æ®" and expected_col == "add_to_cart":
                            self.debug_log.append(f"âŒ [æ•´ä½“æ•°æ®] æœªæ‰¾åˆ° 'åŠ è´­' ç›¸å…³åˆ—ï¼Œå·²å¡«å……ä¸º0ã€‚è¯·æ£€æŸ¥åŸè¡¨åˆ—åã€‚")

                # 5. æ•°
